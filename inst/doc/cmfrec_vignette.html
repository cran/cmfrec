<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="David Cortes" />


<title>Matrix Factorization with Side Info</title>

<script>$(document).ready(function(){
    if (typeof $('[data-toggle="tooltip"]').tooltip === 'function') {
        $('[data-toggle="tooltip"]').tooltip();
    }
    if ($('[data-toggle="popover"]').popover === 'function') {
        $('[data-toggle="popover"]').popover();
    }
});
</script>
<style type="text/css">
.lightable-minimal {
border-collapse: separate;
border-spacing: 16px 1px;
width: 100%;
margin-bottom: 10px;
}
.lightable-minimal td {
margin-left: 5px;
margin-right: 5px;
}
.lightable-minimal th {
margin-left: 5px;
margin-right: 5px;
}
.lightable-minimal thead tr:last-child th {
border-bottom: 2px solid #00000050;
empty-cells: hide;
}
.lightable-minimal tbody tr:first-child td {
padding-top: 0.5em;
}
.lightable-minimal.lightable-hover tbody tr:hover {
background-color: #f5f5f5;
}
.lightable-minimal.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-classic {
border-top: 0.16em solid #111111;
border-bottom: 0.16em solid #111111;
width: 100%;
margin-bottom: 10px;
margin: 10px 5px;
}
.lightable-classic tfoot tr td {
border: 0;
}
.lightable-classic tfoot tr:first-child td {
border-top: 0.14em solid #111111;
}
.lightable-classic caption {
color: #222222;
}
.lightable-classic td {
padding-left: 5px;
padding-right: 5px;
color: #222222;
}
.lightable-classic th {
padding-left: 5px;
padding-right: 5px;
font-weight: normal;
color: #222222;
}
.lightable-classic thead tr:last-child th {
border-bottom: 0.10em solid #111111;
}
.lightable-classic.lightable-hover tbody tr:hover {
background-color: #F9EEC1;
}
.lightable-classic.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-classic-2 {
border-top: 3px double #111111;
border-bottom: 3px double #111111;
width: 100%;
margin-bottom: 10px;
}
.lightable-classic-2 tfoot tr td {
border: 0;
}
.lightable-classic-2 tfoot tr:first-child td {
border-top: 3px double #111111;
}
.lightable-classic-2 caption {
color: #222222;
}
.lightable-classic-2 td {
padding-left: 5px;
padding-right: 5px;
color: #222222;
}
.lightable-classic-2 th {
padding-left: 5px;
padding-right: 5px;
font-weight: normal;
color: #222222;
}
.lightable-classic-2 tbody tr:last-child td {
border-bottom: 3px double #111111;
}
.lightable-classic-2 thead tr:last-child th {
border-bottom: 1px solid #111111;
}
.lightable-classic-2.lightable-hover tbody tr:hover {
background-color: #F9EEC1;
}
.lightable-classic-2.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-material {
min-width: 100%;
white-space: nowrap;
table-layout: fixed;
font-family: Roboto, sans-serif;
border: 1px solid #EEE;
border-collapse: collapse;
margin-bottom: 10px;
}
.lightable-material tfoot tr td {
border: 0;
}
.lightable-material tfoot tr:first-child td {
border-top: 1px solid #EEE;
}
.lightable-material th {
height: 56px;
padding-left: 16px;
padding-right: 16px;
}
.lightable-material td {
height: 52px;
padding-left: 16px;
padding-right: 16px;
border-top: 1px solid #eeeeee;
}
.lightable-material.lightable-hover tbody tr:hover {
background-color: #f5f5f5;
}
.lightable-material.lightable-striped tbody tr:nth-child(even) {
background-color: #f5f5f5;
}
.lightable-material.lightable-striped tbody td {
border: 0;
}
.lightable-material.lightable-striped thead tr:last-child th {
border-bottom: 1px solid #ddd;
}
.lightable-material-dark {
min-width: 100%;
white-space: nowrap;
table-layout: fixed;
font-family: Roboto, sans-serif;
border: 1px solid #FFFFFF12;
border-collapse: collapse;
margin-bottom: 10px;
background-color: #363640;
}
.lightable-material-dark tfoot tr td {
border: 0;
}
.lightable-material-dark tfoot tr:first-child td {
border-top: 1px solid #FFFFFF12;
}
.lightable-material-dark th {
height: 56px;
padding-left: 16px;
padding-right: 16px;
color: #FFFFFF60;
}
.lightable-material-dark td {
height: 52px;
padding-left: 16px;
padding-right: 16px;
color: #FFFFFF;
border-top: 1px solid #FFFFFF12;
}
.lightable-material-dark.lightable-hover tbody tr:hover {
background-color: #FFFFFF12;
}
.lightable-material-dark.lightable-striped tbody tr:nth-child(even) {
background-color: #FFFFFF12;
}
.lightable-material-dark.lightable-striped tbody td {
border: 0;
}
.lightable-material-dark.lightable-striped thead tr:last-child th {
border-bottom: 1px solid #FFFFFF12;
}
.lightable-paper {
width: 100%;
margin-bottom: 10px;
color: #444;
}
.lightable-paper tfoot tr td {
border: 0;
}
.lightable-paper tfoot tr:first-child td {
border-top: 1px solid #00000020;
}
.lightable-paper thead tr:last-child th {
color: #666;
vertical-align: bottom;
border-bottom: 1px solid #00000020;
line-height: 1.15em;
padding: 10px 5px;
}
.lightable-paper td {
vertical-align: middle;
border-bottom: 1px solid #00000010;
line-height: 1.15em;
padding: 7px 5px;
}
.lightable-paper.lightable-hover tbody tr:hover {
background-color: #F9EEC1;
}
.lightable-paper.lightable-striped tbody tr:nth-child(even) {
background-color: #00000008;
}
.lightable-paper.lightable-striped tbody td {
border: 0;
}
</style>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Matrix Factorization with Side Info</h1>
<h4 class="author">David Cortes</h4>


<div id="TOC">
<ul>
<li><a href="#matrix-factorization">Matrix Factorization</a></li>
<li><a href="#loading-the-data">Loading the data</a></li>
<li><a href="#classical-model">Classical model</a></li>
<li><a href="#adding-side-information">Adding side information</a></li>
<li><a href="#generating-top-n-recommendations">Generating Top-N recommendations</a><ul>
<li><a href="#recommendations-for-existing-users">Recommendations for existing users</a></li>
<li><a href="#recommendations-for-new-users">Recommendations for new users</a></li>
<li><a href="#cold-start-recommendations">Cold-start recommendations</a></li>
</ul></li>
</ul>
</div>

<p>This vignette illustrates the usage of the <a href="https://cran.r-project.org/package=cmfrec">cmfrec</a> library for building recommender systems based on collaborative filtering models for explicit-feedback data, with or without side information about the users and items. Note that the library offers also content-based models and implicit-feedback models, but they are not showcased in this vignette.</p>
<p>This example will use the <a href="https://grouplens.org/datasets/movielens/100k/">MovieLens100k</a> data, as bundled in the <a href="https://cran.r-project.org/package=recommenderlab">recommenderlab</a> package, which contains around ~ 100k movie ratings from 943 users about 1664 movies, in a scale from 1 to 5.</p>
<p>In addition to the ratings, it also contains side information about the movies (genre, year of release) and about the users (age, occupation), which will be used here to construct a better recommendation model.</p>
<p><strong>For a more comprehensive introduction see also the <code>cmfrec</code> <a href="https://nbviewer.jupyter.org/github/david-cortes/cmfrec/blob/master/example/cmfrec_movielens_sideinfo.ipynb">Python Notebook</a>, which uses the more richer MovieLens1M instead (not provided by R packages)</strong>.</p>
<div id="matrix-factorization" class="section level2">
<h2>Matrix Factorization</h2>
<p>One of the most popular techniques for building recommender systems is to frame the problem as matrix completion, in which a large sparse matrix is built containing the ratings that users give to products (in this case, movies), with rows representing users, columns representing items, and entries corresponding to the ratings that they’ve given (e.g. “5 stars”). Most of these entries will be missing, as each users is likely to consume only a handful of the available products (thus, the matrix is sparse), and the goal is to construct a model which would be able to predict the value of the known interactions (i.e. predict which rating would each user give to each movie), which is compared against the observed values. The items to recommend to each user are then the ones with highest predicted values among those which the user has not yet consumed.</p>
<p>Typically, the problem is approached by trying to approximate the interactions matrix as the product of two lower-dimension matrices (a.k.a. latent factor matrices), which when multiplied by each other would produce something that resembles the original matrix, having the nice property that it will produce predictions for all user-item combinations - i.e.</p>
<p><span class="math display">\[
\mathbf{X} \approx \mathbf{A} \mathbf{B}^T
\]</span> Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{X}\)</span> is the interactions matrix (users are rows, items are columns).</li>
<li><span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> are the matrices estimated by the model (a.k.a. latent factors), which have a low number of columns, typically 30-100.</li>
</ul>
<p>For a better and more stable model, the <span class="math inline">\(\mathbf{X}\)</span> matrix is typically centered by substracting its mean, a bias/intercept is added for each user and item, and a regularization penalty is applied to the model matrices and biases (typically on the L2 norm) - i.e.:</p>
<p><span class="math display">\[
\mathbf{X} \approx \mathbf{A} \mathbf{B}^T + \mu + \mathbf{b}_A + \mathbf{b}_B
\]</span> Where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the global mean used to center <span class="math inline">\(\mathbf{X}\)</span>.</li>
<li><span class="math inline">\(\mathbf{b}_A\)</span> are user-specific biases (row vector).</li>
<li><span class="math inline">\(\mathbf{b}_B\)</span> are item-specific biases (column vector).</li>
</ul>
<p>The matrices are typically fitted by initializing them to random numbers and then iteratively updating them in a way that decreases the reconstruction error with respect to the observed entries in <span class="math inline">\(\mathbf{X}\)</span>, using either gradient-based procedures (e.g. stochastic gradient descent) or the ALS (alternating least-squares) method, which optimizes one matrix at a time while leaving the other fixed, performing a few sweeps until convergence.</p>
<p>This library (<code>cmfrec</code>) will by default use the ALS method with L2 regularization, and will use user/item biases which are model parameters (updated at each iteration) rather than being pre-estimated.</p>
</div>
<div id="loading-the-data" class="section level2">
<h2>Loading the data</h2>
<p>The MovieLens100k data is taken from the <code>recommenderlab</code> package. As the data is sparse, it is represented as sparse matrices from the <a href="https://cran.r-project.org/package=Matrix">Matrix</a> package. The data comes in CSC format, whereas <code>cmfrec</code> requires COO/triplets format - the conversion is handled by the <a href="https://cran.r-project.org/package=MatrixExtra">MatrixExtra</a> package for convenience, which also provides extra slicing functionality that will be used later.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(cmfrec)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(Matrix)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">library</span>(MatrixExtra)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">library</span>(recommenderlab)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw">data</span>(<span class="st">&quot;MovieLense&quot;</span>)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7">X &lt;-<span class="st"> </span><span class="kw">as.coo.matrix</span>(MovieLense<span class="op">@</span>data)</a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="kw">str</span>(X)</a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="co">#&gt; Formal class 'dgTMatrix' [package &quot;Matrix&quot;] with 6 slots</span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="co">#&gt;   ..@ i       : int [1:99392] 0 1 4 5 9 12 14 15 16 17 ...</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co">#&gt;   ..@ j       : int [1:99392] 0 0 0 0 0 0 0 0 0 0 ...</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="co">#&gt;   ..@ Dim     : int [1:2] 943 1664</span></a>
<a class="sourceLine" id="cb1-13" data-line-number="13"><span class="co">#&gt;   ..@ Dimnames:List of 2</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14"><span class="co">#&gt;   .. ..$ : chr [1:943] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</span></a>
<a class="sourceLine" id="cb1-15" data-line-number="15"><span class="co">#&gt;   .. ..$ : chr [1:1664] &quot;Toy Story (1995)&quot; &quot;GoldenEye (1995)&quot; &quot;Four Rooms (1995)&quot; &quot;Get Shorty (1995)&quot; ...</span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16"><span class="co">#&gt;   ..@ x       : num [1:99392] 5 4 4 4 4 3 1 5 4 5 ...</span></a>
<a class="sourceLine" id="cb1-17" data-line-number="17"><span class="co">#&gt;   ..@ factors : list()</span></a></code></pre></div>
<div id="creating-a-train-test-split" class="section level5">
<h5>Creating a train-test split</h5>
<p>In order to evaluate models, 25% of the data will be set as a test set, while the model will be built with the remainder 75%. The split done here is random, but usually time-based splits tend to reflect more realistic scenarios for recommendation.</p>
<p>Typically, <strong>these splits are done in such a way that the test set contains only users and items which are in the train set</strong>, but such a rule is not necessary and perhaps not even desirable for <code>cmfrec</code>, since it can accomodate global/user/item biases and thus it can make predictions based on them alone.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">subsample_coo_matrix &lt;-<span class="st"> </span><span class="cf">function</span>(X, indices) {</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">    X<span class="op">@</span>i &lt;-<span class="st"> </span>X<span class="op">@</span>i[indices]</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">    X<span class="op">@</span>j &lt;-<span class="st"> </span>X<span class="op">@</span>j[indices]</a>
<a class="sourceLine" id="cb2-4" data-line-number="4">    X<span class="op">@</span>x &lt;-<span class="st"> </span>X<span class="op">@</span>x[indices]</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">    <span class="kw">return</span>(X)</a>
<a class="sourceLine" id="cb2-6" data-line-number="6">}</a>
<a class="sourceLine" id="cb2-7" data-line-number="7"></a>
<a class="sourceLine" id="cb2-8" data-line-number="8">n_ratings &lt;-<span class="st"> </span><span class="kw">length</span>(X<span class="op">@</span>x)</a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb2-10" data-line-number="10">ix_train &lt;-<span class="st"> </span><span class="kw">sample</span>(n_ratings, <span class="kw">floor</span>(<span class="fl">0.75</span> <span class="op">*</span><span class="st"> </span>n_ratings), <span class="dt">replace=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb2-11" data-line-number="11">X_train &lt;-<span class="st"> </span><span class="kw">subsample_coo_matrix</span>(X, ix_train)</a>
<a class="sourceLine" id="cb2-12" data-line-number="12">X_test &lt;-<span class="st"> </span><span class="kw">subsample_coo_matrix</span>(X, <span class="op">-</span>ix_train)</a></code></pre></div>
</div>
</div>
<div id="classical-model" class="section level2">
<h2>Classical model</h2>
<p>Now fitting the classical matrix factorization model, with global mean centering, user/item biases, L2 regularization which scales with the number of ratings for each user/item, and no side information. This is the model explained in the earlier section: <span class="math display">\[
\mathbf{X} \approx \mathbf{A} \mathbf{B}^T + \mu + \mathbf{b}_A + \mathbf{b}_B
\]</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">model.classic &lt;-<span class="st"> </span><span class="kw">CMF</span>(X_train, <span class="dt">k=</span><span class="dv">25</span>, <span class="dt">lambda=</span><span class="fl">0.1</span>, <span class="dt">scale_lam=</span><span class="ot">TRUE</span>, <span class="dt">verbose=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<div id="how-good-is-it" class="section level4">
<h4>How good is it?</h4>
<p>The most typical way of evaluating the quality of these models is by evaluating the error that they have at predicting known entries, which here will be evaluated against the test data that was set apart earlier. The evaluation here will be done in terms of mean squared error (RMSE).</p>
<p><strong>Note that, while widely used in the early literature for recommender systems, RMSE might not provide a good overview of the ranking of items (which is what matters for recommendations), and it’s recommended to also evaluate other metrics such as <code>NDCG@K</code>, <code>P@K</code>, correlations, etc.</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">print_rmse &lt;-<span class="st"> </span><span class="cf">function</span>(X_test, X_hat, model_name) {</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">  rmse &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>( (X_test<span class="op">@</span>x <span class="op">-</span><span class="st"> </span>X_hat<span class="op">@</span>x)<span class="op">^</span><span class="dv">2</span> ))</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">  <span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">&quot;RMSE for %s is: %.4f</span><span class="ch">\n</span><span class="st">&quot;</span>, model_name, rmse))</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">}</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">pred_classic &lt;-<span class="st"> </span><span class="kw">predict</span>(model.classic, X_test)</a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="kw">print_rmse</span>(X_test, pred_classic, <span class="st">&quot;classic model&quot;</span>)</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"><span class="co">#&gt; RMSE for classic model is: 0.9243</span></a></code></pre></div>
<p>i.e. it means that the ratings are off by about one star. This is better than a non-personalized model that would always predict the same rating for each user, which can also be simulated through <code>cmfrec</code>:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">model.baseline &lt;-<span class="st"> </span><span class="kw">MostPopular</span>(X_train, <span class="dt">lambda=</span><span class="dv">10</span>, <span class="dt">scale_lam=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">pred_baseline &lt;-<span class="st"> </span><span class="kw">predict</span>(model.baseline, X_test)</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="kw">print_rmse</span>(X_test, pred_baseline, <span class="st">&quot;non-personalized model&quot;</span>)</a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="co">#&gt; RMSE for non-personalized model is: 0.9460</span></a></code></pre></div>
<p>(<em>Note: it’s not recommended to use scaled/dynamic regularization in a most-popular model, as it will tend to recommend items with only one user giving the maximum rating.</em>)</p>
</div>
<div id="improving-the-classical-model" class="section level4">
<h4>Improving the classical model</h4>
<p>By default, ALS-based models are broken down to small problems involving linear systems, which are in turned solved through the <a href="http://rs1.sze.hu/~gtakacs/download/recsys_2011_draft.pdf">Conjugate Gradient</a> method, but <code>cmfrec</code> can also use a Cholesky solver for them, which is slower but tends to result in better-quality solutions for explicit-feedback.</p>
<p>As well, the default number of iterations is 10, but can be increased for better models at the expense of longer fitting times.</p>
<p>But more importantly, <code>cmfrec</code> offers the option of adding “implicit-features” or co-factoring, which will additionally factorize binarized versions of <span class="math inline">\(\mathbf{X}\)</span> (telling whether each entry is missing or not), sharing the same latent components with the factorization of <span class="math inline">\(\mathbf{X}\)</span> - that is: <span class="math display">\[
\mathbf{X} \approx \mathbf{A} \mathbf{B}^T + \mu + \mathbf{b}_A + \mathbf{b}_B
\]</span> <span class="math display">\[
\mathbf{I}_x \approx \mathbf{A} \mathbf{B}^T_i
\:\:\:\:
\mathbf{I}^T_x \approx \mathbf{B} \mathbf{A}^T_i
\]</span> Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{I}_x\)</span> is a binary matrix indicating whether each entry of <span class="math inline">\(\mathbf{X}\)</span> is observed or missing.</li>
<li><span class="math inline">\(\mathbf{A}_i\)</span> and <span class="math inline">\(\mathbf{B}_i\)</span> are model matrices which are not directly used for <span class="math inline">\(\mathbf{X}\)</span>, and not used in the prediction formula, but are still estimated in this new multi-objective optimization objective.</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">model.improved &lt;-<span class="st"> </span><span class="kw">CMF</span>(X_train, <span class="dt">k=</span><span class="dv">25</span>, <span class="dt">lambda=</span><span class="fl">0.1</span>, <span class="dt">scale_lam=</span><span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">                      <span class="dt">add_implicit_features=</span><span class="ot">TRUE</span>, <span class="dt">w_main=</span><span class="fl">0.75</span>, <span class="dt">w_implicit=</span><span class="fl">0.25</span>,</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">                      <span class="dt">use_cg=</span><span class="ot">FALSE</span>, <span class="dt">niter=</span><span class="dv">30</span>, <span class="dt">verbose=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb6-4" data-line-number="4">pred_improved &lt;-<span class="st"> </span><span class="kw">predict</span>(model.improved, X_test)</a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="kw">print_rmse</span>(X_test, pred_improved, <span class="st">&quot;improved classic model&quot;</span>)</a></code></pre></div>
<pre><code>#&gt; RMSE for improved classic model is: 0.9128</code></pre>
</div>
</div>
<div id="adding-side-information" class="section level2">
<h2>Adding side information</h2>
<p>Collective matrix factorization extends the classical model by incorporating side information about users/items into the formula, which is done by also factorizing the side information matrices, sharing the same latent components that are used for factorizing the <span class="math inline">\(\mathbf{X}\)</span> matrix: <span class="math display">\[
\mathbf{X} \approx \mathbf{A} \mathbf{B}^T + \mu + \mathbf{b}_A + \mathbf{b}_B
\]</span> <span class="math display">\[
\mathbf{U} \approx \mathbf{A} \mathbf{C}^T + \mu_U
\]</span> <span class="math display">\[
\mathbf{I} \approx \mathbf{B} \mathbf{D}^T + \mu_I
\]</span> <span class="math display">\[
\mathbf{I}_x \approx \mathbf{A} \mathbf{B}^T_i
\:\:\:\:
\mathbf{I}^T_x \approx \mathbf{B} \mathbf{A}^T_i
\]</span> Where:</p>
<ul>
<li><span class="math inline">\(\mathbf{U}\)</span> is a matrix representing side information about users, with each user being a row, and columns corresponding to their attributes.</li>
<li><span class="math inline">\(\mathbf{I}\)</span> is similarly a matrix representing side information about items.</li>
<li><span class="math inline">\(\mathbf{C}\)</span> and <span class="math inline">\(\mathbf{D}\)</span> are new latent factor matrices used for factorizing the side information matrices, but are not used directly for <span class="math inline">\(\mathbf{X}\)</span>.</li>
<li><span class="math inline">\(\mu_U\)</span> and <span class="math inline">\(\mu_I\)</span> are column means for the attributes, which are used in order to center them.</li>
</ul>
<p>Informally, the latent factors now need to explain both the interactions data as well as the side information, thereby making them generalize better to unseen data. This library in addition allows controlling aspects such as the weight that each factorization has in the optimization objective, different regularization for each matrix, having factors that are not shared, among others.</p>
<hr />
<p>Fetching the side information from <code>recommenderlab</code>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">U &lt;-<span class="st"> </span>MovieLenseUser</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">U<span class="op">$</span>id      &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">U<span class="op">$</span>zipcode &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4">U<span class="op">$</span>age2    &lt;-<span class="st"> </span>U<span class="op">$</span>age<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"><span class="co">### Note that `cmfrec` does not standardize features beyond mean centering</span></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">U<span class="op">$</span>age     &lt;-<span class="st"> </span>(U<span class="op">$</span>age <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(U<span class="op">$</span>age)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(U<span class="op">$</span>age)</a>
<a class="sourceLine" id="cb8-7" data-line-number="7">U<span class="op">$</span>age2    &lt;-<span class="st"> </span>(U<span class="op">$</span>age2 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(U<span class="op">$</span>age2)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(U<span class="op">$</span>age2)</a>
<a class="sourceLine" id="cb8-8" data-line-number="8">U &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span>.<span class="op">-</span><span class="dv">1</span>, <span class="dt">data=</span>U)</a>
<a class="sourceLine" id="cb8-9" data-line-number="9"></a>
<a class="sourceLine" id="cb8-10" data-line-number="10">I &lt;-<span class="st"> </span>MovieLenseMeta</a>
<a class="sourceLine" id="cb8-11" data-line-number="11">I<span class="op">$</span>title &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb8-12" data-line-number="12">I<span class="op">$</span>url   &lt;-<span class="st"> </span><span class="ot">NULL</span></a>
<a class="sourceLine" id="cb8-13" data-line-number="13">I<span class="op">$</span>year  &lt;-<span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">is.na</span>(I<span class="op">$</span>year), <span class="kw">median</span>(I<span class="op">$</span>year, <span class="dt">na.rm=</span><span class="ot">TRUE</span>), I<span class="op">$</span>year)</a>
<a class="sourceLine" id="cb8-14" data-line-number="14">I<span class="op">$</span>year2 &lt;-<span class="st"> </span>I<span class="op">$</span>year<span class="op">^</span><span class="dv">2</span></a>
<a class="sourceLine" id="cb8-15" data-line-number="15">I<span class="op">$</span>year  &lt;-<span class="st"> </span>(I<span class="op">$</span>year <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(I<span class="op">$</span>year)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(I<span class="op">$</span>year)</a>
<a class="sourceLine" id="cb8-16" data-line-number="16">I<span class="op">$</span>year2 &lt;-<span class="st"> </span>(I<span class="op">$</span>year2 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(I<span class="op">$</span>year2)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(I<span class="op">$</span>year2)</a>
<a class="sourceLine" id="cb8-17" data-line-number="17">I &lt;-<span class="st"> </span><span class="kw">as.coo.matrix</span>(I)</a>
<a class="sourceLine" id="cb8-18" data-line-number="18"></a>
<a class="sourceLine" id="cb8-19" data-line-number="19"><span class="kw">cat</span>(<span class="kw">dim</span>(U), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb8-20" data-line-number="20"><span class="co">#&gt; 943 24</span></a>
<a class="sourceLine" id="cb8-21" data-line-number="21"><span class="kw">cat</span>(<span class="kw">dim</span>(I), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb8-22" data-line-number="22"><span class="co">#&gt; 1664 21</span></a></code></pre></div>
<p>Now fitting the model:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">model.w.sideinfo &lt;-<span class="st"> </span><span class="kw">CMF</span>(X_train, <span class="dt">U=</span>U, <span class="dt">I=</span>I, <span class="dt">NA_as_zero_item=</span><span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">                        <span class="dt">k=</span><span class="dv">25</span>, <span class="dt">lambda=</span><span class="fl">0.1</span>, <span class="dt">scale_lam=</span><span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">                        <span class="dt">niter=</span><span class="dv">30</span>, <span class="dt">use_cg=</span><span class="ot">FALSE</span>, <span class="dt">include_all_X=</span><span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">                        <span class="dt">w_main=</span><span class="fl">0.75</span>, <span class="dt">w_user=</span><span class="fl">0.5</span>, <span class="dt">w_item=</span><span class="fl">0.5</span>, <span class="dt">w_implicit=</span><span class="fl">0.5</span>,</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">                        <span class="dt">verbose=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb9-6" data-line-number="6">pred_side_info &lt;-<span class="st"> </span><span class="kw">predict</span>(model.w.sideinfo, X_test)</a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="kw">print_rmse</span>(X_test, pred_side_info, <span class="st">&quot;model with side info&quot;</span>)</a></code></pre></div>
<pre><code>#&gt; RMSE for model with side info is: 0.9099</code></pre>
<hr />
<p>Summary:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">library</span>(kableExtra)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"></a>
<a class="sourceLine" id="cb11-3" data-line-number="3">calc_rmse &lt;-<span class="st"> </span><span class="cf">function</span>(X_test, X_hat) {</a>
<a class="sourceLine" id="cb11-4" data-line-number="4">    <span class="kw">return</span>(<span class="kw">sqrt</span>(<span class="kw">mean</span>( (X_test<span class="op">@</span>x <span class="op">-</span><span class="st"> </span>X_hat<span class="op">@</span>x)<span class="op">^</span><span class="dv">2</span> )))</a>
<a class="sourceLine" id="cb11-5" data-line-number="5">}</a>
<a class="sourceLine" id="cb11-6" data-line-number="6">results &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb11-7" data-line-number="7">    <span class="dt">NonPersonalized =</span> <span class="kw">calc_rmse</span>(X_test, pred_baseline),</a>
<a class="sourceLine" id="cb11-8" data-line-number="8">    <span class="dt">ClassicalModel =</span> <span class="kw">calc_rmse</span>(X_test, pred_classic),</a>
<a class="sourceLine" id="cb11-9" data-line-number="9">    <span class="dt">ClassicPlusImplicit =</span> <span class="kw">calc_rmse</span>(X_test, pred_improved),</a>
<a class="sourceLine" id="cb11-10" data-line-number="10">    <span class="dt">CollectiveModel =</span> <span class="kw">calc_rmse</span>(X_test, pred_side_info)</a>
<a class="sourceLine" id="cb11-11" data-line-number="11">)</a>
<a class="sourceLine" id="cb11-12" data-line-number="12">results &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">t</span>(results))</a>
<a class="sourceLine" id="cb11-13" data-line-number="13"><span class="kw">names</span>(results) &lt;-<span class="st"> &quot;RMSE&quot;</span></a>
<a class="sourceLine" id="cb11-14" data-line-number="14">results <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb11-15" data-line-number="15"><span class="st">    </span><span class="kw">kable</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb11-16" data-line-number="16"><span class="st">    </span><span class="kw">kable_styling</span>()</a></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
RMSE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
NonPersonalized
</td>
<td style="text-align:right;">
0.9460112
</td>
</tr>
<tr>
<td style="text-align:left;">
ClassicalModel
</td>
<td style="text-align:right;">
0.9242721
</td>
</tr>
<tr>
<td style="text-align:left;">
ClassicPlusImplicit
</td>
<td style="text-align:right;">
0.9128036
</td>
</tr>
<tr>
<td style="text-align:left;">
CollectiveModel
</td>
<td style="text-align:right;">
0.9098834
</td>
</tr>
</tbody>
</table>
<p>Important to keep in mind:</p>
<ul>
<li>These RMSEs have high standard errors due to the small amount of data used here.</li>
<li>The model hyperparameters are not particularly tuned, and a proper tuning should use a validation split too.</li>
<li>The test split is using users and items which might not have been in the training set.</li>
<li>While it looks like the difference from adding side information is very small, it also comes with the side effect of being able to recommend items based on attributes.</li>
<li>RMSE as a metric can hide overfitting in models that tend to recommend items with too few ratings/interactions - these models in particular will tend to recommend many movies with only a handful ratings, which is typically undesirable. A model with higher regularization that shows higher test RMSE might in practice produce better quality recommendations (see the introductory <a href="https://nbviewer.jupyter.org/github/david-cortes/cmfrec/blob/master/example/cmfrec_movielens_sideinfo.ipynb">Python notebook</a> for more examples on this topic).</li>
<li>The models evaluated so far have all used dynamic/scaled regularization (as proposed in <a href="https://link.springer.com/chapter/10.1007/978-3-540-68880-8_32">Large-scale Parallel Collaborative Filtering for the Netflix Prize</a>), save for the baseline most-popular model - this means that the regularization for each user and item is scaled by the number of present entries for it. This setting tends to produce dubious recommendations in small datasets like the MovieLens100k, even if it makes it look like it improves RMSE.</li>
</ul>
</div>
<div id="generating-top-n-recommendations" class="section level2">
<h2>Generating Top-N recommendations</h2>
<p>The goal behind building a collaborative filtering model is typically to be able to make top-N recommended lists for users or to obtain latent factors for an unseen user given its current data. <code>cmfrec</code> has many prediction functions for these purposes depending on what specifically one wants to do, supporting both warm-start and cold-start recommendations.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="co">### Re-fitting the earlier model to all the data,</span></a>
<a class="sourceLine" id="cb12-2" data-line-number="2"><span class="co">### this time *without* scaled regularization</span></a>
<a class="sourceLine" id="cb12-3" data-line-number="3">model.classic &lt;-<span class="st"> </span><span class="kw">CMF</span>(X, <span class="dt">k=</span><span class="dv">20</span>, <span class="dt">lambda=</span><span class="dv">10</span>, <span class="dt">scale_lam=</span><span class="ot">FALSE</span>, <span class="dt">verbose=</span><span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">model.w.sideinfo &lt;-<span class="st"> </span><span class="kw">CMF</span>(X, <span class="dt">U=</span>U, <span class="dt">I=</span>I, <span class="dt">k=</span><span class="dv">20</span>, <span class="dt">lambda=</span><span class="dv">10</span>, <span class="dt">scale_lam=</span><span class="ot">FALSE</span>,</a>
<a class="sourceLine" id="cb12-5" data-line-number="5">                        <span class="dt">w_main=</span><span class="fl">0.75</span>, <span class="dt">w_user=</span><span class="fl">0.125</span>, <span class="dt">w_item=</span><span class="fl">0.125</span>,</a>
<a class="sourceLine" id="cb12-6" data-line-number="6">                        <span class="dt">verbose=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<div id="recommendations-for-existing-users" class="section level3">
<h3>Recommendations for existing users</h3>
<p>When fitting a model, all the necessary fitted matrices are saved inside the object itself, which allows making predictions for existing users based just on the ID. The specific items consumed by each user are however not saved, so in order to avoid recommending already-seen items, these have to be explicitly passed for exclusion.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">user_to_recommend &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="co">### Note: slicing of 'X' is provided by 'MatrixExtra',</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="co">### returning a 'sparseVector' object as required by cmfrec</span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="kw">topN</span>(model.classic, <span class="dt">user=</span>user_to_recommend, <span class="dt">n=</span><span class="dv">10</span>,</a>
<a class="sourceLine" id="cb13-5" data-line-number="5">     <span class="dt">exclude=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>])</a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="co">#&gt;  [1] 316 424 524 405 169  89  79 511 187   8</span></a></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="co">### A handy function for visualizing recommendations</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2">movie_names &lt;-<span class="st"> </span><span class="kw">colnames</span>(X)</a>
<a class="sourceLine" id="cb14-3" data-line-number="3">n_ratings &lt;-<span class="st"> </span><span class="kw">colSums</span>(<span class="kw">as.csc.matrix</span>(X, <span class="dt">binary=</span><span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">avg_ratings &lt;-<span class="st"> </span><span class="kw">colSums</span>(<span class="kw">as.csc.matrix</span>(X)) <span class="op">/</span><span class="st"> </span>n_ratings</a>
<a class="sourceLine" id="cb14-5" data-line-number="5">print_recommended &lt;-<span class="st"> </span><span class="cf">function</span>(rec, txt) {</a>
<a class="sourceLine" id="cb14-6" data-line-number="6">    <span class="kw">cat</span>(txt, <span class="st">&quot;:</span><span class="ch">\n</span><span class="st">&quot;</span>,</a>
<a class="sourceLine" id="cb14-7" data-line-number="7">        <span class="kw">paste</span>(<span class="kw">paste</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(rec), <span class="st">&quot;. &quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>),</a>
<a class="sourceLine" id="cb14-8" data-line-number="8">              movie_names[rec],</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">              <span class="st">&quot; - Avg rating:&quot;</span>, <span class="kw">round</span>(avg_ratings[rec], <span class="dv">2</span>),</a>
<a class="sourceLine" id="cb14-10" data-line-number="10">              <span class="st">&quot;, #ratings: &quot;</span>, n_ratings[rec],</a>
<a class="sourceLine" id="cb14-11" data-line-number="11">              <span class="dt">collapse=</span><span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>),</a>
<a class="sourceLine" id="cb14-12" data-line-number="12">        <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)</a>
<a class="sourceLine" id="cb14-13" data-line-number="13">}</a>
<a class="sourceLine" id="cb14-14" data-line-number="14">recommended &lt;-<span class="st"> </span><span class="kw">topN</span>(model.w.sideinfo, <span class="dt">user=</span>user_to_recommend, <span class="dt">n=</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb14-15" data-line-number="15">                    <span class="dt">exclude=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>])</a>
<a class="sourceLine" id="cb14-16" data-line-number="16"><span class="kw">print_recommended</span>(recommended, <span class="st">&quot;Recommended for user_id=10&quot;</span>)</a>
<a class="sourceLine" id="cb14-17" data-line-number="17"><span class="co">#&gt; Recommended for user_id=10:</span></a>
<a class="sourceLine" id="cb14-18" data-line-number="18"><span class="co">#&gt; 1. Schindler's List (1993) - Avg rating:4.47, #ratings: 298</span></a>
<a class="sourceLine" id="cb14-19" data-line-number="19"><span class="co">#&gt; 2. To Kill a Mockingbird (1962) - Avg rating:4.29, #ratings: 219</span></a>
<a class="sourceLine" id="cb14-20" data-line-number="20"><span class="co">#&gt; 3. Close Shave, A (1995) - Avg rating:4.49, #ratings: 112</span></a>
<a class="sourceLine" id="cb14-21" data-line-number="21"><span class="co">#&gt; 4. Wrong Trousers, The (1993) - Avg rating:4.47, #ratings: 118</span></a>
<a class="sourceLine" id="cb14-22" data-line-number="22"><span class="co">#&gt; 5. Boot, Das (1981) - Avg rating:4.2, #ratings: 201</span></a></code></pre></div>
</div>
<div id="recommendations-for-new-users" class="section level3">
<h3>Recommendations for new users</h3>
<p>The fitted model, as it is, can only provide recommendations for the specific users and items to which it was fit. Typically, one wants to produce recommendations for new users as they go, or update the recommended lists for existing users once they consume more items. <code>cmfrec</code> allows obtaining latent factors and top-N recommended lists for new users without having to refit the whole model.</p>
<p>This is how it would be if user 10 were to come as a new visitor:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">recommended_new &lt;-<span class="st"> </span><span class="kw">topN_new</span>(model.w.sideinfo, <span class="dt">n=</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">                            <span class="dt">exclude=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>],</a>
<a class="sourceLine" id="cb15-3" data-line-number="3">                            <span class="dt">X=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>],</a>
<a class="sourceLine" id="cb15-4" data-line-number="4">                            <span class="dt">U=</span>U[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>])</a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="kw">print_recommended</span>(recommended_new, <span class="st">&quot;Recommended for user_id=10 as new user&quot;</span>)</a>
<a class="sourceLine" id="cb15-6" data-line-number="6"><span class="co">#&gt; Recommended for user_id=10 as new user:</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7"><span class="co">#&gt; 1. Schindler's List (1993) - Avg rating:4.47, #ratings: 298</span></a>
<a class="sourceLine" id="cb15-8" data-line-number="8"><span class="co">#&gt; 2. To Kill a Mockingbird (1962) - Avg rating:4.29, #ratings: 219</span></a>
<a class="sourceLine" id="cb15-9" data-line-number="9"><span class="co">#&gt; 3. Close Shave, A (1995) - Avg rating:4.49, #ratings: 112</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10"><span class="co">#&gt; 4. Wrong Trousers, The (1993) - Avg rating:4.47, #ratings: 118</span></a>
<a class="sourceLine" id="cb15-11" data-line-number="11"><span class="co">#&gt; 5. Boot, Das (1981) - Avg rating:4.2, #ratings: 201</span></a></code></pre></div>
<p>It is not mandatory to provide all the side information, as the ratings alone can also be used to generate a recommendation, even if the model was fit with side information (this would not be the case if passing <code>NA_as_zero_user=TRUE</code>):</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">recommended_new &lt;-<span class="st"> </span><span class="kw">topN_new</span>(model.w.sideinfo, <span class="dt">n=</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb16-2" data-line-number="2">                            <span class="dt">exclude=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>],</a>
<a class="sourceLine" id="cb16-3" data-line-number="3">                            <span class="dt">X=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>])</a>
<a class="sourceLine" id="cb16-4" data-line-number="4"><span class="kw">print_recommended</span>(recommended_new, <span class="st">&quot;Recommended for user_id=10 as new user (NO sideinfo)&quot;</span>)</a>
<a class="sourceLine" id="cb16-5" data-line-number="5"><span class="co">#&gt; Recommended for user_id=10 as new user (NO sideinfo):</span></a>
<a class="sourceLine" id="cb16-6" data-line-number="6"><span class="co">#&gt; 1. Schindler's List (1993) - Avg rating:4.47, #ratings: 298</span></a>
<a class="sourceLine" id="cb16-7" data-line-number="7"><span class="co">#&gt; 2. To Kill a Mockingbird (1962) - Avg rating:4.29, #ratings: 219</span></a>
<a class="sourceLine" id="cb16-8" data-line-number="8"><span class="co">#&gt; 3. Close Shave, A (1995) - Avg rating:4.49, #ratings: 112</span></a>
<a class="sourceLine" id="cb16-9" data-line-number="9"><span class="co">#&gt; 4. Wrong Trousers, The (1993) - Avg rating:4.47, #ratings: 118</span></a>
<a class="sourceLine" id="cb16-10" data-line-number="10"><span class="co">#&gt; 5. Boot, Das (1981) - Avg rating:4.2, #ratings: 201</span></a></code></pre></div>
<p>(<em>In this case, the top-5 recommendations did not change, as the side information has little effect in this particular model, but that might not always be the case - that is, the top-N recommended items for a different user might be different if side information is absent.</em>)</p>
</div>
<div id="cold-start-recommendations" class="section level3">
<h3>Cold-start recommendations</h3>
<p>Conversely, it is also possible to make a recommendation based on the side information without having any rated movies/items. The quality of these recommendations is however highly dependant on the influence that the attributes have in the model, and in this case, the user attributes have very little associated information and thus little leverage.</p>
<p>Nevertheless, they might still provide an improvement over a completely non-personalized recommendation (see <a href="https://arxiv.org/pdf/1809.00366.pdf">Cold-start recommendations in Collective Matrix Factorization</a>):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">recommended_cold &lt;-<span class="st"> </span><span class="kw">topN_new</span>(model.w.sideinfo, <span class="dt">n=</span><span class="dv">5</span>,</a>
<a class="sourceLine" id="cb17-2" data-line-number="2">                             <span class="dt">exclude=</span>X[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>],</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">                             <span class="dt">U=</span>U[user_to_recommend, , <span class="dt">drop=</span><span class="ot">TRUE</span>])</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="kw">print_recommended</span>(recommended_cold, <span class="st">&quot;Recommended for user_id=10 as new user (NO ratings)&quot;</span>)</a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="co">#&gt; Recommended for user_id=10 as new user (NO ratings):</span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6"><span class="co">#&gt; 1. Schindler's List (1993) - Avg rating:4.47, #ratings: 298</span></a>
<a class="sourceLine" id="cb17-7" data-line-number="7"><span class="co">#&gt; 2. Close Shave, A (1995) - Avg rating:4.49, #ratings: 112</span></a>
<a class="sourceLine" id="cb17-8" data-line-number="8"><span class="co">#&gt; 3. Wrong Trousers, The (1993) - Avg rating:4.47, #ratings: 118</span></a>
<a class="sourceLine" id="cb17-9" data-line-number="9"><span class="co">#&gt; 4. Good Will Hunting (1997) - Avg rating:4.26, #ratings: 198</span></a>
<a class="sourceLine" id="cb17-10" data-line-number="10"><span class="co">#&gt; 5. Wallace &amp; Gromit: The Best of Aardman Animation (1996) - Avg rating:4.45, #ratings: 67</span></a></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
